{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706\n",
      "(706, 144)\n",
      "82\n",
      "(82, 129)\n",
      "167\n",
      "(167, 129)\n",
      "187\n",
      "(187, 129)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"./feature/class.xlsx\")\n",
    "# print(df)\n",
    "dataset_list = [\"tongji\", \"xiangyang\", \"kits\", \"henan\"]\n",
    "for dataset in dataset_list:\n",
    "    df_csv = pd.read_excel(\"./feature/ring/\" + dataset + \"_ring5.xlsx\", index_col=0)\n",
    "    namelist = df[(df[\"dataset\"] == dataset) & (df[\"exclusion\"] == 1)][\"name\"].values\n",
    "    # 批量去掉.npy\n",
    "    namelist = [name[:-4] for name in namelist]\n",
    "    new_namelist = df_csv.index\n",
    "    for name in namelist:\n",
    "        if name in new_namelist:\n",
    "            continue\n",
    "        else:\n",
    "            print(dataset, name)\n",
    "\n",
    "    print(len(namelist))\n",
    "    # tongji_list = namelist\n",
    "    csv = df_csv.loc[namelist, :]\n",
    "    print(csv.shape)\n",
    "    csv.to_excel(\"./feature/ring/ring_\" + dataset + \".xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['RONG ZONG AN', 'TJH0334', 'TJH0346', 'TJH0811', 'GUO RAN FU',\n",
      "       'YU TAO XIANG', 'JIN HAI YI', 'TJH0072', 'TJH0832', 'TJH0731',\n",
      "       ...\n",
      "       'ZHOU ZE MIN', 'XIE BIN', 'TJH0606', 'TJH0026', 'DENG XUAN YONG',\n",
      "       'CHEN YANG GUI', 'WANG SHENG HUA', 'TJH0369', 'TJH0357', 'TJH0543'],\n",
      "      dtype='object', length=706) Index(['FAN XUE YING', 'LIU WEI', 'LIU YING E', 'CHEN ZHI GANG', 'LIN RUI LAN',\n",
      "       'WANG GUO BIN', 'WU HUI XIANG', 'DAN BI ZHONG', 'GAO HUI PING',\n",
      "       'WANG YING ZHEN',\n",
      "       ...\n",
      "       'SHEN RUI', 'WANG ZU WEI', 'ZHENG MEI JIAO', 'LI YAN XIONG', 'YAO WEI',\n",
      "       'BAO CHAO', 'QIU XIAO DONG', 'YI WEN HUA', 'XUE HONG', 'YAO SHANG YI'],\n",
      "      dtype='object', length=578)\n",
      "XU REN DOU\n",
      "(941, 144)\n"
     ]
    }
   ],
   "source": [
    "tj1 = pd.read_csv(\"./feature/ring_5.csv\", index_col=0)\n",
    "\n",
    "tj2 = pd.read_excel(\"./feature/tongji_ring5.xlsx\", index_col=0)\n",
    "# tj2的index去掉.nii.gz\n",
    "tj2.index = [name[:-7] for name in tj2.index]\n",
    "print(tj1.index, tj2.index)\n",
    "if \"XU REN DOU\" in tj2.index:\n",
    "    if \"XU REN DOU\" in tj1.index:\n",
    "        print(\"XU REN DOU\")\n",
    "\n",
    "# 查看tj1和tj2相同的index\n",
    "same_index = tj1.index.intersection(tj2.index)\n",
    "# 去掉tj2中相同的index\n",
    "tj2 = tj2.drop(same_index)\n",
    "\n",
    "# index去掉XU REN DOU项\n",
    "# tj2 = tj2.drop(\"XU REN DOU\", axis=0)\n",
    "# print(tj1.index)\n",
    "tj = pd.concat([tj1, tj2])\n",
    "print(tj.shape)\n",
    "tj.to_excel(\"./feature/rad/ring_tongji.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(707, 144)\n",
      "707\n",
      "706\n",
      "706\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "tj = pd.read_excel(\"./feature/rad/rad_tongji.xlsx\", index_col=0)\n",
    "print(tj.shape)\n",
    "tj_list = tj.index\n",
    "print(len(tj_list))\n",
    "print(len(tongji_list))\n",
    "print(len(set(tj_list)))\n",
    "missing_in_tongji = set(tj_list) - set(tongji_list)\n",
    "print(missing_in_tongji)\n",
    "# for name in tj_list:\n",
    "#     if name in tongji_list:\n",
    "#         continue\n",
    "#     else:\n",
    "#         print(\"tj_list\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "重复的项：\n",
      "XU REN DOU: 出现 2 次\n",
      "\n",
      "重复项及其位置：\n",
      "XU REN DOU: 在位置 [501, 502] 出现\n"
     ]
    }
   ],
   "source": [
    "# 方法1：使用collections.Counter\n",
    "from collections import Counter\n",
    "\n",
    "# 查找重复项及其出现次数\n",
    "duplicates = [item for item, count in Counter(tj_list).items() if count > 1]\n",
    "print(\"重复的项：\")\n",
    "for item in duplicates:\n",
    "    print(f\"{item}: 出现 {Counter(tj_list)[item]} 次\")\n",
    "\n",
    "# # 方法2：使用set比较\n",
    "# print(\"重复的个数：\", len(tongji_list) - len(set(tongji_list)))\n",
    "\n",
    "# 方法3：更详细的方法，显示重复项的索引\n",
    "duplicates_dict = {}\n",
    "for i, item in enumerate(tj_list):\n",
    "    if item in duplicates_dict:\n",
    "        duplicates_dict[item].append(i)\n",
    "    else:\n",
    "        duplicates_dict[item] = [i]\n",
    "\n",
    "print(\"\\n重复项及其位置：\")\n",
    "for item, indices in duplicates_dict.items():\n",
    "    if len(indices) > 1:\n",
    "        print(f\"{item}: 在位置 {indices} 出现\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# select k best features\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "# import models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, matthews_corrcoef\n",
    "from sklearn.metrics import precision_recall_curve, auc, precision_score, recall_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "def bootstrap_ci(metric_func, y_prob, y_true, n_iterations=1000, ci=0.95):\n",
    "    \"\"\"\n",
    "    计算bootstrap置信区间\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_prob = np.array(y_prob)\n",
    "    size = len(y_true)\n",
    "    scores = []\n",
    "    \n",
    "    rng = np.random.RandomState(42)  # 设置随机种子\n",
    "    \n",
    "    for _ in range(n_iterations):\n",
    "        # 随机抽样（使用替换）\n",
    "        indices = rng.randint(0, size, size=size)\n",
    "        score = metric_func(y_true[indices], y_prob[indices])\n",
    "        scores.append(score)\n",
    "    \n",
    "    # 计算置信区间\n",
    "    sorted_scores = np.sort(scores)\n",
    "    alpha = (1 - ci) / 2\n",
    "    lower_bound = sorted_scores[int(alpha * n_iterations)]\n",
    "    upper_bound = sorted_scores[int((1 - alpha) * n_iterations)]\n",
    "    \n",
    "    return (lower_bound, upper_bound)\n",
    "\n",
    "def calculate_metrics(y_prob, y_true):\n",
    "    \"\"\"\n",
    "    计算不平衡二分类问题的评价指标，包括95%置信区间\n",
    "    \n",
    "    参数：\n",
    "    y_prob: numpy array, 预测为正类(少数类)的概率值\n",
    "    y_true: numpy array, 真实标签 (0为多数类，1为少数类)\n",
    "    \n",
    "    返回：\n",
    "    dict: 包含评价指标和置信区间的字典\n",
    "    \"\"\"\n",
    "    # 1. AUC\n",
    "    auc_score = roc_auc_score(y_true, y_prob)\n",
    "    auc_ci = bootstrap_ci(roc_auc_score, y_prob, y_true)\n",
    "    \n",
    "    # 2. 通过优化F1-score选择最佳阈值\n",
    "    # precisions, recalls, thresholds = precision_recall_curve(y_true, y_prob)\n",
    "    # f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "    # f1_scores = np.nan_to_num(f1_scores)\n",
    "    # best_threshold = thresholds[np.argmax(f1_scores[:-1])]\n",
    "    best_threshold = 0.5\n",
    "    \n",
    "    # 使用最佳阈值进行预测\n",
    "    y_pred = (y_prob >= best_threshold).astype(int)\n",
    "    \n",
    "    # 3. F1-score\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    f1_ci = bootstrap_ci(lambda y_t, y_p: f1_score(y_t, (y_p >= best_threshold).astype(int)),\n",
    "                        y_prob, y_true)\n",
    "    \n",
    "    # 4. ACC\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    acc_ci = bootstrap_ci(lambda y_t, y_p: accuracy_score(y_t, (y_p >= best_threshold).astype(int)),\n",
    "                         y_prob, y_true)\n",
    "    \n",
    "    # 5. MCC\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    mcc_ci = bootstrap_ci(lambda y_t, y_p: matthews_corrcoef(y_t, (y_p >= best_threshold).astype(int)),\n",
    "                         y_prob, y_true)\n",
    "    \n",
    "    # 6. AUPRC\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
    "    auprc = auc(recall, precision)\n",
    "    \n",
    "    def auprc_score(y_t, y_p):\n",
    "        p, r, _ = precision_recall_curve(y_t, y_p)\n",
    "        return auc(r, p)\n",
    "    \n",
    "    auprc_ci = bootstrap_ci(auprc_score, y_prob, y_true)\n",
    "    \n",
    "    # 7. Precision\n",
    "    precisionscore = precision_score(y_true, y_pred)\n",
    "    precision_ci = bootstrap_ci(lambda y_t, y_p: precision_score(y_t, (y_p >= best_threshold).astype(int)),\n",
    "                              y_prob, y_true)\n",
    "\n",
    "    # 8. Recall\n",
    "    recallscore = recall_score(y_true, y_pred)\n",
    "    recall_ci = bootstrap_ci(lambda y_t, y_p: recall_score(y_t, (y_p >= best_threshold).astype(int)),\n",
    "                            y_prob, y_true)\n",
    "\n",
    "    metrics = {\n",
    "        'AUC': round(auc_score, 3),\n",
    "        'AUC_CI': auc_ci,\n",
    "        'F1': round(f1, 3),\n",
    "        'F1_CI': f1_ci,\n",
    "        'ACC': round(acc, 3),\n",
    "        'ACC_CI': acc_ci,\n",
    "        'MCC': round(mcc, 3),\n",
    "        'MCC_CI': mcc_ci,\n",
    "        'AUPRC': round(auprc, 3),\n",
    "        'AUPRC_CI': auprc_ci,\n",
    "        # 'threshold': round(best_threshold, 3),\n",
    "        'Precision': round(precisionscore, 3),\n",
    "        'Precision_CI': precision_ci,\n",
    "        'Recall': round(recallscore, 3),\n",
    "        'Recall_CI': recall_ci\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def format_metrics(metrics):\n",
    "    \"\"\"\n",
    "    格式化指标输出，包含置信区间\n",
    "    \"\"\"\n",
    "    formatted = {}\n",
    "    for key in metrics:\n",
    "        if key.endswith('_CI'):\n",
    "            continue\n",
    "        if key + '_CI' in metrics:\n",
    "            formatted[key] = f\"{metrics[key]} ({metrics[key+'_CI'][0]}-{metrics[key+'_CI'][1]})\"\n",
    "        else:\n",
    "            formatted[key] = f\"{metrics[key]}\"\n",
    "    \n",
    "    return formatted\n",
    "\n",
    "def merge_dicts_to_df(*dicts):\n",
    "    \"\"\"\n",
    "    将多个评估指标字典合并为一个DataFrame\n",
    "    \n",
    "    参数:\n",
    "    *dicts: 多个包含评估指标的字典\n",
    "    \n",
    "    返回:\n",
    "    merged_df: 合并后的DataFrame\n",
    "    \"\"\"\n",
    "    # 创建空的DataFrame保存所有结果\n",
    "    merged_df = pd.DataFrame()\n",
    "    \n",
    "    # 创建索引列表\n",
    "    new_index = ['train', 'inter_test', 'henan_test', 'kits_test']\n",
    "    \n",
    "    # 遍历所有字典\n",
    "    for i, d in enumerate(dicts, 1):\n",
    "        # 提取主要指标\n",
    "        metrics = {\n",
    "            'AUC': d['AUC'],\n",
    "            'AUC_CI': f\"({d['AUC_CI'][0]:.3f}-{d['AUC_CI'][1]:.3f})\",\n",
    "            'AUPRC': d['AUPRC'],\n",
    "            'AUPRC_CI': f\"({d['AUPRC_CI'][0]:.3f}-{d['AUPRC_CI'][1]:.3f})\",\n",
    "            'F1': d['F1'],\n",
    "            'F1_CI': f\"({d['F1_CI'][0]:.3f}-{d['F1_CI'][1]:.3f})\",\n",
    "            'ACC': d['ACC'],\n",
    "            'ACC_CI': f\"({d['ACC_CI'][0]:.3f}-{d['ACC_CI'][1]:.3f})\",\n",
    "            'MCC': d['MCC'],\n",
    "            'MCC_CI': f\"({d['MCC_CI'][0]:.3f}-{d['MCC_CI'][1]:.3f})\",\n",
    "            'Precision': d['Precision'],\n",
    "            'Precision_CI': f\"({d['Precision_CI'][0]:.3f}-{d['Precision_CI'][1]:.3f})\",\n",
    "            'Recall': d['Recall'],\n",
    "            'Recall_CI': f\"({d['Recall_CI'][0]:.3f}-{d['Recall_CI'][1]:.3f})\",\n",
    "        }\n",
    "        \n",
    "        # 转换为DataFrame并添加模型标识\n",
    "        df = pd.DataFrame([metrics])\n",
    "        \n",
    "        # 合并到主DataFrame\n",
    "        merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "    \n",
    "    # 重排列columns\n",
    "    column_order = ['AUC', 'AUC_CI', 'AUPRC', 'AUPRC_CI', \n",
    "                    'F1', 'F1_CI', 'ACC', 'ACC_CI', 'MCC', 'MCC_CI',\n",
    "                    'Precision', 'Precision_CI', 'Recall', 'Recall_CI']\n",
    "    merged_df = merged_df[column_order]\n",
    "    \n",
    "    # 添加索引列\n",
    "    merged_df.insert(0, 'Dataset', new_index)\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AUC': 0.992, 'AUC_CI': (0.9854700854700854, 0.9971321080547675), 'F1': 0.832, 'F1_CI': (0.7450980392156863, 0.8992248062015504), 'ACC': 0.966, 'ACC_CI': (0.9491833030852994, 0.9800362976406534), 'MCC': 0.815, 'MCC_CI': (0.7215331409930178, 0.8901268046829179), 'AUPRC': 0.927, 'AUPRC_CI': (0.8523392426413096, 0.9753783215994241), 'Precision': 0.887, 'Precision_CI': (0.7916666666666666, 0.9636363636363636), 'Recall': 0.783, 'Recall_CI': (0.6716417910447762, 0.8857142857142857)}\n",
      "{'AUC': 0.709, 'AUC_CI': (0.6087636932707355, 0.8159603554340396), 'F1': 0.242, 'F1_CI': (0.0625, 0.4375), 'ACC': 0.895, 'ACC_CI': (0.8523206751054853, 0.9324894514767933), 'MCC': 0.258, 'MCC_CI': (0.046318664634473566, 0.4602192772174345), 'AUPRC': 0.289, 'AUPRC_CI': (0.1373498465081574, 0.47225314424758846), 'Precision': 0.571, 'Precision_CI': (0.2, 1.0), 'Recall': 0.154, 'Recall_CI': (0.034482758620689655, 0.3157894736842105)}\n",
      "{'AUC': 0.633, 'AUC_CI': (0.5224483204134367, 0.7285206718346253), 'F1': 0.128, 'F1_CI': (0.0, 0.2622950819672131), 'ACC': 0.781, 'ACC_CI': (0.7219251336898396, 0.839572192513369), 'MCC': 0.183, 'MCC_CI': (-0.03702901775859789, 0.32948275215227624), 'AUPRC': 0.385, 'AUPRC_CI': (0.24885202597301515, 0.540512009152222), 'Precision': 0.75, 'Precision_CI': (0.0, 1.0), 'Recall': 0.07, 'Recall_CI': (0.0, 0.15789473684210525)}\n",
      "{'AUC': 0.661, 'AUC_CI': (0.5512820512820512, 0.7697874265038445), 'F1': 0.167, 'F1_CI': (0.0, 0.33333333333333337), 'ACC': 0.82, 'ACC_CI': (0.7604790419161677, 0.874251497005988), 'MCC': 0.187, 'MCC_CI': (-0.05151970522569787, 0.3740103394691893), 'AUPRC': 0.305, 'AUPRC_CI': (0.19022675302094422, 0.484327954422393), 'Precision': 0.6, 'Precision_CI': (0.0, 1.0), 'Recall': 0.097, 'Recall_CI': (0.0, 0.21875)}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 读取proba和gt\n",
    "\n",
    "data = pd.read_excel(\"./result/ring.xlsx\")\n",
    "\n",
    "y_train = data[data['dataset'] == 'train']['ground_truth']\n",
    "y_val = data[data['dataset'] == 'val']['ground_truth']\n",
    "y_henan = data[data['dataset'] == 'henan']['ground_truth']\n",
    "y_kits = data[data['dataset'] == 'kits']['ground_truth']\n",
    "\n",
    "proba_train = data[data['dataset'] == 'train']['probability']\n",
    "proba_val = data[data['dataset'] == 'val']['probability']\n",
    "proba_henan = data[data['dataset'] == 'henan']['probability']\n",
    "proba_kits = data[data['dataset'] == 'kits']['probability']\n",
    "\n",
    "# 计算评估指标\n",
    "result_train = calculate_metrics(proba_train, y_train)\n",
    "result_val = calculate_metrics(proba_val, y_val)\n",
    "result_henan = calculate_metrics(proba_henan, y_henan)\n",
    "result_kits = calculate_metrics(proba_kits, y_kits)\n",
    "print(result_train)\n",
    "print(result_val)\n",
    "print(result_henan)\n",
    "print(result_kits)\n",
    "\n",
    "# 合并字典\n",
    "merged_results = merge_dicts_to_df(result_train, result_val, result_henan, result_kits)\n",
    "\n",
    "# 保存为CSV文件\n",
    "merged_results.to_excel('results_ring.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (roc_curve, precision_recall_curve, average_precision_score,\n",
    "                           roc_auc_score, confusion_matrix, classification_report)\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "def plot_classifier_evaluation_separate(y_true, y_prob, save_path=None):\n",
    "    \"\"\"\n",
    "    分别绘制并保存分类器评估图\n",
    "    \n",
    "    参数:\n",
    "    y_true: 真实标签 (0/1)\n",
    "    y_prob: 预测概率\n",
    "    save_path: PDF保存路径\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. ROC曲线\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    \n",
    "    plt.plot(fpr, tpr, 'b-', label=f'ROC (AUC = {auc:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Random')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    if save_path:\n",
    "        plt.savefig(f'{save_path}_roc.pdf')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. PR曲线\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
    "    ap = average_precision_score(y_true, y_prob)\n",
    "    \n",
    "    plt.plot(recall, precision, 'b-', label=f'PR (AP = {ap:.3f})')\n",
    "    plt.axhline(y=sum(y_true)/len(y_true), color='r', linestyle='--', label='Random')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    if save_path:\n",
    "        plt.savefig(f'{save_path}_pr.pdf')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. 预测概率分布\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for label, color in zip([0, 1], ['red', 'blue']):\n",
    "        mask = y_true == label\n",
    "        plt.hist(y_prob[mask], bins=50, density=True, alpha=0.5, \n",
    "                color=color, label=f'Class {label}')\n",
    "    plt.xlabel('Predicted Probability')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title('Probability Distribution')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    if save_path:\n",
    "        plt.savefig(f'{save_path}_prob_dist.pdf')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. 分类阈值分析\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "    scores = []\n",
    "    for thresh in thresholds:\n",
    "        y_pred = (y_prob >= thresh).astype(int)\n",
    "        tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "        fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "        fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "        tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "        \n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        scores.append([accuracy, precision, recall, f1])\n",
    "    \n",
    "    scores = np.array(scores)\n",
    "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.plot(thresholds, scores[:, i], label=metric)\n",
    "    plt.xlabel('Classification Threshold')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Metric Scores vs Classification Threshold')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    if save_path:\n",
    "        plt.savefig(f'{save_path}_threshold.pdf')\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. 校准曲线\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    prob_true, prob_pred = calibration_curve(y_true, y_prob, n_bins=10)\n",
    "    plt.plot(prob_pred, prob_true, 's-', label='Calibration curve')\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Perfect calibration')\n",
    "    plt.xlabel('Mean predicted probability')\n",
    "    plt.ylabel('Fraction of positives')\n",
    "    plt.title('Calibration Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    if save_path:\n",
    "        plt.savefig(f'{save_path}_calibration.pdf')\n",
    "    plt.close()\n",
    "    \n",
    "    # 6. 混淆矩阵\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    if save_path:\n",
    "        plt.savefig(f'{save_path}_confusion.pdf')\n",
    "    plt.close()\n",
    "    \n",
    "    # # 7. 分类瀑布图\n",
    "    # plt.figure(figsize=(12, 6))\n",
    "    # sorted_indices = np.argsort(y_prob)\n",
    "    # sorted_probs = y_prob[sorted_indices]\n",
    "    # sorted_true = y_true[sorted_indices]\n",
    "    \n",
    "    # plt.plot(range(len(sorted_probs)), sorted_probs, 'b-', label='Predicted probability')\n",
    "    # plt.scatter(range(len(sorted_true)), sorted_true, c='r', alpha=0.5, \n",
    "    #            label='True label', marker='.')\n",
    "    # plt.axhline(y=0.5, color='g', linestyle='--', label='Decision threshold')\n",
    "    # plt.xlabel('Samples (sorted by predicted probability)')\n",
    "    # plt.ylabel('Probability / Class')\n",
    "    # plt.title('Classification Waterfall Plot')\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "    # if save_path:\n",
    "    #     plt.savefig(f'{save_path}_waterfall.pdf')\n",
    "    # plt.close()\n",
    "    \n",
    "    # return {\n",
    "    #     'AUC': auc,\n",
    "    #     'AP': ap,\n",
    "    #     'Confusion Matrix': cm,\n",
    "    #     'Classification Report': classification_report(y_true, y_pred)\n",
    "    # }\n",
    "\n",
    "# 使用示例:\n",
    "plot_classifier_evaluation_separate(y_val, proba_val, save_path='inter_test')\n",
    "plot_classifier_evaluation_separate(y_henan, proba_henan, save_path='henan_test')\n",
    "plot_classifier_evaluation_separate(y_kits, proba_kits, save_path='kits_test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
