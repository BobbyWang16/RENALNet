{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据\n",
    "# 对比五个简单的分类器\n",
    "# import mrmr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(478, 4096) (206, 4096) (478, 1) (206, 1)\n"
     ]
    }
   ],
   "source": [
    "tongji_data = pd.read_csv('./feature/tongji/dl_feature_tongji.csv', index_col=0).iloc[:, 3:]\n",
    "xiangyang_data = pd.read_csv('./feature/xiangyang/dl_feature_xiangyang.csv', index_col=0).iloc[:, 3:]\n",
    "kits_data = pd.read_csv('./feature/kits/dl_feature_kits.csv', index_col=0).iloc[:, 3:]\n",
    "henan_data = pd.read_csv('./feature/henan/dl_feature_henan.csv', index_col=0).iloc[:, 3:]\n",
    "# index使用最后一个作为索引\n",
    "tongji_data.index = tongji_data.index.str.split('/').str[-1]\n",
    "tongji_data.index = tongji_data.index.str.split('.').str[0]\n",
    "xiangyang_data.index = xiangyang_data.index.str.split('/').str[-1]\n",
    "xiangyang_data.index = xiangyang_data.index.str.split('.').str[0]\n",
    "kits_data.index = kits_data.index.str.split('/').str[-1]\n",
    "kits_data.index = kits_data.index.str.split('.').str[0]\n",
    "henan_data.index = henan_data.index.str.split('/').str[-1]\n",
    "henan_data.index = henan_data.index.str.split('.').str[0]\n",
    "\n",
    "tongji_label = pd.read_csv('./feature/tongji/tongji.csv', index_col=0)\n",
    "xiangyang_label = pd.read_csv('./feature/xiangyang/xiangyang.csv', index_col=0)\n",
    "kits_label = pd.read_csv('./feature/kits/kits.csv', index_col=0)\n",
    "henan_label = pd.read_csv('./feature/henan/henan.csv', index_col=0)\n",
    "\n",
    "feature_data = pd.concat([tongji_data, xiangyang_data], axis=0)\n",
    "feature_label = pd.concat([tongji_label, xiangyang_label], axis=0)\n",
    "\n",
    "# 数据分组\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_data, feature_label, test_size=0.3, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-03.\n",
      "Adjusting learning rate of group 0 to 4.9988e-03.\n",
      "Epoch 1/100\n",
      "Train Loss: 0.1574, Acc: 0.5607\n",
      "Val Loss: 0.1057, Acc: 0.7233, AUC: 0.3867\n",
      "Val Precision: 0.0250, Recall: 0.0526, F1: 0.0339\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.9952e-03.\n",
      "Epoch 2/100\n",
      "Train Loss: 0.1051, Acc: 0.6862\n",
      "Val Loss: 0.0877, Acc: 0.8252, AUC: 0.5356\n",
      "Val Precision: 0.1304, Recall: 0.1579, F1: 0.1429\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.9891e-03.\n",
      "Epoch 3/100\n",
      "Train Loss: 0.0859, Acc: 0.8013\n",
      "Val Loss: 0.0709, Acc: 0.9078, AUC: 0.4444\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.9807e-03.\n",
      "Epoch 4/100\n",
      "Train Loss: 0.0715, Acc: 0.8598\n",
      "Val Loss: 0.0644, Acc: 0.9078, AUC: 0.5916\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.9698e-03.\n",
      "Epoch 5/100\n",
      "Train Loss: 0.0650, Acc: 0.8745\n",
      "Val Loss: 0.0676, Acc: 0.9078, AUC: 0.3991\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.9566e-03.\n",
      "Epoch 6/100\n",
      "Train Loss: 0.0727, Acc: 0.8661\n",
      "Val Loss: 0.0660, Acc: 0.8981, AUC: 0.5260\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.9410e-03.\n",
      "Epoch 7/100\n",
      "Train Loss: 0.0705, Acc: 0.8891\n",
      "Val Loss: 0.0651, Acc: 0.9078, AUC: 0.4557\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.9230e-03.\n",
      "Epoch 8/100\n",
      "Train Loss: 0.0666, Acc: 0.8745\n",
      "Val Loss: 0.0662, Acc: 0.9078, AUC: 0.4439\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.9027e-03.\n",
      "Epoch 9/100\n",
      "Train Loss: 0.0635, Acc: 0.8828\n",
      "Val Loss: 0.0702, Acc: 0.8883, AUC: 0.4833\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.8801e-03.\n",
      "Epoch 10/100\n",
      "Train Loss: 0.0648, Acc: 0.8849\n",
      "Val Loss: 0.0649, Acc: 0.9078, AUC: 0.4703\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.8552e-03.\n",
      "Epoch 11/100\n",
      "Train Loss: 0.0591, Acc: 0.8912\n",
      "Val Loss: 0.0675, Acc: 0.9078, AUC: 0.4585\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.8280e-03.\n",
      "Epoch 12/100\n",
      "Train Loss: 0.0583, Acc: 0.8933\n",
      "Val Loss: 0.0690, Acc: 0.9029, AUC: 0.4287\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.7985e-03.\n",
      "Epoch 13/100\n",
      "Train Loss: 0.0597, Acc: 0.8828\n",
      "Val Loss: 0.0652, Acc: 0.9078, AUC: 0.5435\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.7668e-03.\n",
      "Epoch 14/100\n",
      "Train Loss: 0.0566, Acc: 0.8808\n",
      "Val Loss: 0.0714, Acc: 0.9078, AUC: 0.4289\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.7330e-03.\n",
      "Epoch 15/100\n",
      "Train Loss: 0.0532, Acc: 0.8954\n",
      "Val Loss: 0.0738, Acc: 0.8835, AUC: 0.4985\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.6970e-03.\n",
      "Epoch 16/100\n",
      "Train Loss: 0.0548, Acc: 0.8703\n",
      "Val Loss: 0.0753, Acc: 0.8981, AUC: 0.4925\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.6588e-03.\n",
      "Epoch 17/100\n",
      "Train Loss: 0.0486, Acc: 0.9017\n",
      "Val Loss: 0.0732, Acc: 0.8835, AUC: 0.4782\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.6186e-03.\n",
      "Epoch 18/100\n",
      "Train Loss: 0.0492, Acc: 0.8912\n",
      "Val Loss: 0.0736, Acc: 0.8981, AUC: 0.5055\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.5763e-03.\n",
      "Epoch 19/100\n",
      "Train Loss: 0.0470, Acc: 0.9142\n",
      "Val Loss: 0.0721, Acc: 0.8981, AUC: 0.5531\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.5321e-03.\n",
      "Epoch 20/100\n",
      "Train Loss: 0.0428, Acc: 0.9038\n",
      "Val Loss: 0.0758, Acc: 0.8883, AUC: 0.5328\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.4859e-03.\n",
      "Epoch 21/100\n",
      "Train Loss: 0.0419, Acc: 0.9059\n",
      "Val Loss: 0.0805, Acc: 0.8738, AUC: 0.5722\n",
      "Val Precision: 0.1111, Recall: 0.0526, F1: 0.0714\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.4378e-03.\n",
      "Epoch 22/100\n",
      "Train Loss: 0.0361, Acc: 0.9163\n",
      "Val Loss: 0.0996, Acc: 0.8689, AUC: 0.4264\n",
      "Val Precision: 0.1000, Recall: 0.0526, F1: 0.0690\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.3878e-03.\n",
      "Epoch 23/100\n",
      "Train Loss: 0.0404, Acc: 0.9289\n",
      "Val Loss: 0.0862, Acc: 0.8398, AUC: 0.6639\n",
      "Val Precision: 0.1818, Recall: 0.2105, F1: 0.1951\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.3360e-03.\n",
      "Epoch 24/100\n",
      "Train Loss: 0.0351, Acc: 0.9205\n",
      "Val Loss: 0.0960, Acc: 0.8495, AUC: 0.5151\n",
      "Val Precision: 0.1250, Recall: 0.1053, F1: 0.1143\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.2824e-03.\n",
      "Epoch 25/100\n",
      "Train Loss: 0.0373, Acc: 0.9163\n",
      "Val Loss: 0.1030, Acc: 0.8495, AUC: 0.4925\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.2271e-03.\n",
      "Epoch 26/100\n",
      "Train Loss: 0.0278, Acc: 0.9268\n",
      "Val Loss: 0.0862, Acc: 0.8981, AUC: 0.5559\n",
      "Val Precision: 0.3333, Recall: 0.1053, F1: 0.1600\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.1702e-03.\n",
      "Epoch 27/100\n",
      "Train Loss: 0.0305, Acc: 0.9372\n",
      "Val Loss: 0.0992, Acc: 0.8544, AUC: 0.6001\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.1117e-03.\n",
      "Epoch 28/100\n",
      "Train Loss: 0.0367, Acc: 0.9331\n",
      "Val Loss: 0.1001, Acc: 0.8447, AUC: 0.5761\n",
      "Val Precision: 0.1905, Recall: 0.2105, F1: 0.2000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.0516e-03.\n",
      "Epoch 29/100\n",
      "Train Loss: 0.0317, Acc: 0.9268\n",
      "Val Loss: 0.0929, Acc: 0.8689, AUC: 0.4678\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 3.9901e-03.\n",
      "Epoch 30/100\n",
      "Train Loss: 0.0231, Acc: 0.9477\n",
      "Val Loss: 0.1263, Acc: 0.7961, AUC: 0.5238\n",
      "Val Precision: 0.0741, Recall: 0.1053, F1: 0.0870\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 3.9271e-03.\n",
      "Epoch 31/100\n",
      "Train Loss: 0.0240, Acc: 0.9540\n",
      "Val Loss: 0.0883, Acc: 0.8786, AUC: 0.6237\n",
      "Val Precision: 0.2500, Recall: 0.1579, F1: 0.1935\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 3.8628e-03.\n",
      "Epoch 32/100\n",
      "Train Loss: 0.0287, Acc: 0.9351\n",
      "Val Loss: 0.1107, Acc: 0.8301, AUC: 0.5460\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 3.7972e-03.\n",
      "Epoch 33/100\n",
      "Train Loss: 0.0268, Acc: 0.9414\n",
      "Val Loss: 0.1163, Acc: 0.8592, AUC: 0.5469\n",
      "Val Precision: 0.1875, Recall: 0.1579, F1: 0.1714\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 3.7303e-03.\n",
      "Epoch 34/100\n",
      "Train Loss: 0.0343, Acc: 0.9310\n",
      "Val Loss: 0.1075, Acc: 0.8786, AUC: 0.5457\n",
      "Val Precision: 0.1250, Recall: 0.0526, F1: 0.0741\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 3.6623e-03.\n",
      "Epoch 35/100\n",
      "Train Loss: 0.0394, Acc: 0.9121\n",
      "Val Loss: 0.0970, Acc: 0.8447, AUC: 0.5367\n",
      "Val Precision: 0.0667, Recall: 0.0526, F1: 0.0588\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 3.5932e-03.\n",
      "Epoch 36/100\n",
      "Train Loss: 0.0266, Acc: 0.9477\n",
      "Val Loss: 0.0972, Acc: 0.8981, AUC: 0.5668\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 3.5230e-03.\n",
      "Epoch 37/100\n",
      "Train Loss: 0.0160, Acc: 0.9749\n",
      "Val Loss: 0.1078, Acc: 0.8883, AUC: 0.5137\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 3.4519e-03.\n",
      "Epoch 38/100\n",
      "Train Loss: 0.0178, Acc: 0.9686\n",
      "Val Loss: 0.1159, Acc: 0.8155, AUC: 0.6167\n",
      "Val Precision: 0.1200, Recall: 0.1579, F1: 0.1364\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 3.3799e-03.\n",
      "Epoch 39/100\n",
      "Train Loss: 0.0149, Acc: 0.9707\n",
      "Val Loss: 0.0980, Acc: 0.8495, AUC: 0.6772\n",
      "Val Precision: 0.1667, Recall: 0.1579, F1: 0.1622\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 3.3071e-03.\n",
      "Epoch 40/100\n",
      "Train Loss: 0.0344, Acc: 0.9351\n",
      "Val Loss: 0.1469, Acc: 0.8398, AUC: 0.4866\n",
      "Val Precision: 0.1111, Recall: 0.1053, F1: 0.1081\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 3.2335e-03.\n",
      "Epoch 41/100\n",
      "Train Loss: 0.0378, Acc: 0.9247\n",
      "Val Loss: 0.1005, Acc: 0.8301, AUC: 0.6293\n",
      "Val Precision: 0.1667, Recall: 0.2105, F1: 0.1860\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 3.1593e-03.\n",
      "Epoch 42/100\n",
      "Train Loss: 0.0257, Acc: 0.9498\n",
      "Val Loss: 0.1085, Acc: 0.8398, AUC: 0.5041\n",
      "Val Precision: 0.1111, Recall: 0.1053, F1: 0.1081\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 3.0845e-03.\n",
      "Epoch 43/100\n",
      "Train Loss: 0.0207, Acc: 0.9603\n",
      "Val Loss: 0.1137, Acc: 0.8689, AUC: 0.5111\n",
      "Val Precision: 0.2500, Recall: 0.2105, F1: 0.2286\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 3.0091e-03.\n",
      "Epoch 44/100\n",
      "Train Loss: 0.0186, Acc: 0.9644\n",
      "Val Loss: 0.1090, Acc: 0.8786, AUC: 0.5789\n",
      "Val Precision: 0.1250, Recall: 0.0526, F1: 0.0741\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.9333e-03.\n",
      "Epoch 45/100\n",
      "Train Loss: 0.0175, Acc: 0.9686\n",
      "Val Loss: 0.1301, Acc: 0.9029, AUC: 0.4768\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.8571e-03.\n",
      "Epoch 46/100\n",
      "Train Loss: 0.0268, Acc: 0.9498\n",
      "Val Loss: 0.1367, Acc: 0.8252, AUC: 0.6240\n",
      "Val Precision: 0.1852, Recall: 0.2632, F1: 0.2174\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.7806e-03.\n",
      "Epoch 47/100\n",
      "Train Loss: 0.0231, Acc: 0.9665\n",
      "Val Loss: 0.1236, Acc: 0.8544, AUC: 0.5604\n",
      "Val Precision: 0.2105, Recall: 0.2105, F1: 0.2105\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.7038e-03.\n",
      "Epoch 48/100\n",
      "Train Loss: 0.0228, Acc: 0.9540\n",
      "Val Loss: 0.1284, Acc: 0.8592, AUC: 0.4610\n",
      "Val Precision: 0.0833, Recall: 0.0526, F1: 0.0645\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.6270e-03.\n",
      "Epoch 49/100\n",
      "Train Loss: 0.0275, Acc: 0.9372\n",
      "Val Loss: 0.1189, Acc: 0.8447, AUC: 0.5091\n",
      "Val Precision: 0.1905, Recall: 0.2105, F1: 0.2000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.5500e-03.\n",
      "Epoch 50/100\n",
      "Train Loss: 0.0286, Acc: 0.9351\n",
      "Val Loss: 0.1095, Acc: 0.8495, AUC: 0.5390\n",
      "Val Precision: 0.0714, Recall: 0.0526, F1: 0.0606\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.4730e-03.\n",
      "Epoch 51/100\n",
      "Train Loss: 0.0196, Acc: 0.9603\n",
      "Val Loss: 0.1113, Acc: 0.8883, AUC: 0.5502\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.3962e-03.\n",
      "Epoch 52/100\n",
      "Train Loss: 0.0183, Acc: 0.9749\n",
      "Val Loss: 0.1258, Acc: 0.8835, AUC: 0.5063\n",
      "Val Precision: 0.1429, Recall: 0.0526, F1: 0.0769\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.3194e-03.\n",
      "Epoch 53/100\n",
      "Train Loss: 0.0164, Acc: 0.9707\n",
      "Val Loss: 0.1229, Acc: 0.8932, AUC: 0.5722\n",
      "Val Precision: 0.2000, Recall: 0.0526, F1: 0.0833\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.2429e-03.\n",
      "Epoch 54/100\n",
      "Train Loss: 0.0153, Acc: 0.9707\n",
      "Val Loss: 0.1267, Acc: 0.8786, AUC: 0.4838\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.1667e-03.\n",
      "Epoch 55/100\n",
      "Train Loss: 0.0128, Acc: 0.9791\n",
      "Val Loss: 0.1121, Acc: 0.8932, AUC: 0.5792\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0909e-03.\n",
      "Epoch 56/100\n",
      "Train Loss: 0.0080, Acc: 0.9874\n",
      "Val Loss: 0.1226, Acc: 0.8641, AUC: 0.5733\n",
      "Val Precision: 0.1538, Recall: 0.1053, F1: 0.1250\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0155e-03.\n",
      "Epoch 57/100\n",
      "Train Loss: 0.0139, Acc: 0.9770\n",
      "Val Loss: 0.1185, Acc: 0.8835, AUC: 0.6195\n",
      "Val Precision: 0.2222, Recall: 0.1053, F1: 0.1429\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.9407e-03.\n",
      "Epoch 58/100\n",
      "Train Loss: 0.0133, Acc: 0.9707\n",
      "Val Loss: 0.1341, Acc: 0.8689, AUC: 0.5528\n",
      "Val Precision: 0.2143, Recall: 0.1579, F1: 0.1818\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.8665e-03.\n",
      "Epoch 59/100\n",
      "Train Loss: 0.0188, Acc: 0.9644\n",
      "Val Loss: 0.1532, Acc: 0.7864, AUC: 0.5629\n",
      "Val Precision: 0.1429, Recall: 0.2632, F1: 0.1852\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.7929e-03.\n",
      "Epoch 60/100\n",
      "Train Loss: 0.0247, Acc: 0.9498\n",
      "Val Loss: 0.1152, Acc: 0.8835, AUC: 0.5494\n",
      "Val Precision: 0.2727, Recall: 0.1579, F1: 0.2000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.7201e-03.\n",
      "Epoch 61/100\n",
      "Train Loss: 0.0185, Acc: 0.9623\n",
      "Val Loss: 0.1255, Acc: 0.8738, AUC: 0.5055\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.6481e-03.\n",
      "Epoch 62/100\n",
      "Train Loss: 0.0152, Acc: 0.9686\n",
      "Val Loss: 0.1107, Acc: 0.8835, AUC: 0.5778\n",
      "Val Precision: 0.1429, Recall: 0.0526, F1: 0.0769\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.5770e-03.\n",
      "Epoch 63/100\n",
      "Train Loss: 0.0098, Acc: 0.9874\n",
      "Val Loss: 0.1267, Acc: 0.8932, AUC: 0.5362\n",
      "Val Precision: 0.2000, Recall: 0.0526, F1: 0.0833\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.5068e-03.\n",
      "Epoch 64/100\n",
      "Train Loss: 0.0119, Acc: 0.9854\n",
      "Val Loss: 0.1362, Acc: 0.8592, AUC: 0.5170\n",
      "Val Precision: 0.0833, Recall: 0.0526, F1: 0.0645\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.4377e-03.\n",
      "Epoch 65/100\n",
      "Train Loss: 0.0151, Acc: 0.9644\n",
      "Val Loss: 0.1173, Acc: 0.8932, AUC: 0.6088\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.3697e-03.\n",
      "Epoch 66/100\n",
      "Train Loss: 0.0101, Acc: 0.9854\n",
      "Val Loss: 0.1192, Acc: 0.8981, AUC: 0.5584\n",
      "Val Precision: 0.3333, Recall: 0.1053, F1: 0.1600\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.3028e-03.\n",
      "Epoch 67/100\n",
      "Train Loss: 0.0090, Acc: 0.9854\n",
      "Val Loss: 0.1184, Acc: 0.8689, AUC: 0.5908\n",
      "Val Precision: 0.2143, Recall: 0.1579, F1: 0.1818\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.2372e-03.\n",
      "Epoch 68/100\n",
      "Train Loss: 0.0058, Acc: 0.9895\n",
      "Val Loss: 0.1332, Acc: 0.8689, AUC: 0.5981\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.1729e-03.\n",
      "Epoch 69/100\n",
      "Train Loss: 0.0050, Acc: 0.9958\n",
      "Val Loss: 0.1392, Acc: 0.8981, AUC: 0.5021\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.1099e-03.\n",
      "Epoch 70/100\n",
      "Train Loss: 0.0050, Acc: 0.9895\n",
      "Val Loss: 0.1226, Acc: 0.8786, AUC: 0.5888\n",
      "Val Precision: 0.1250, Recall: 0.0526, F1: 0.0741\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.0484e-03.\n",
      "Epoch 71/100\n",
      "Train Loss: 0.0103, Acc: 0.9833\n",
      "Val Loss: 0.1248, Acc: 0.8835, AUC: 0.5621\n",
      "Val Precision: 0.2222, Recall: 0.1053, F1: 0.1429\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 9.8831e-04.\n",
      "Epoch 72/100\n",
      "Train Loss: 0.0085, Acc: 0.9874\n",
      "Val Loss: 0.1426, Acc: 0.8883, AUC: 0.4678\n",
      "Val Precision: 0.2500, Recall: 0.1053, F1: 0.1481\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 9.2979e-04.\n",
      "Epoch 73/100\n",
      "Train Loss: 0.0110, Acc: 0.9812\n",
      "Val Loss: 0.1281, Acc: 0.9078, AUC: 0.5359\n",
      "Val Precision: 0.5000, Recall: 0.0526, F1: 0.0952\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 8.7286e-04.\n",
      "Epoch 74/100\n",
      "Train Loss: 0.0192, Acc: 0.9665\n",
      "Val Loss: 0.1321, Acc: 0.8786, AUC: 0.5787\n",
      "Val Precision: 0.1250, Recall: 0.0526, F1: 0.0741\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 8.1759e-04.\n",
      "Epoch 75/100\n",
      "Train Loss: 0.0100, Acc: 0.9833\n",
      "Val Loss: 0.1379, Acc: 0.8835, AUC: 0.5072\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 7.6403e-04.\n",
      "Epoch 76/100\n",
      "Train Loss: 0.0039, Acc: 0.9979\n",
      "Val Loss: 0.1395, Acc: 0.8786, AUC: 0.5426\n",
      "Val Precision: 0.1250, Recall: 0.0526, F1: 0.0741\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 7.1223e-04.\n",
      "Epoch 77/100\n",
      "Train Loss: 0.0047, Acc: 0.9958\n",
      "Val Loss: 0.1392, Acc: 0.8786, AUC: 0.5404\n",
      "Val Precision: 0.1250, Recall: 0.0526, F1: 0.0741\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 6.6224e-04.\n",
      "Epoch 78/100\n",
      "Train Loss: 0.0040, Acc: 0.9958\n",
      "Val Loss: 0.1441, Acc: 0.8835, AUC: 0.5322\n",
      "Val Precision: 0.1429, Recall: 0.0526, F1: 0.0769\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 6.1412e-04.\n",
      "Epoch 79/100\n",
      "Train Loss: 0.0027, Acc: 0.9958\n",
      "Val Loss: 0.1444, Acc: 0.8835, AUC: 0.5207\n",
      "Val Precision: 0.1429, Recall: 0.0526, F1: 0.0769\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.6791e-04.\n",
      "Epoch 80/100\n",
      "Train Loss: 0.0059, Acc: 0.9895\n",
      "Val Loss: 0.1375, Acc: 0.8932, AUC: 0.5297\n",
      "Val Precision: 0.2000, Recall: 0.0526, F1: 0.0833\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.2365e-04.\n",
      "Epoch 81/100\n",
      "Train Loss: 0.0061, Acc: 0.9874\n",
      "Val Loss: 0.1363, Acc: 0.8932, AUC: 0.5778\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.8140e-04.\n",
      "Epoch 82/100\n",
      "Train Loss: 0.0041, Acc: 0.9937\n",
      "Val Loss: 0.1413, Acc: 0.8641, AUC: 0.6065\n",
      "Val Precision: 0.0909, Recall: 0.0526, F1: 0.0667\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.4118e-04.\n",
      "Epoch 83/100\n",
      "Train Loss: 0.0028, Acc: 0.9958\n",
      "Val Loss: 0.1381, Acc: 0.8883, AUC: 0.5584\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 4.0305e-04.\n",
      "Epoch 84/100\n",
      "Train Loss: 0.0027, Acc: 0.9979\n",
      "Val Loss: 0.1402, Acc: 0.8932, AUC: 0.5590\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 3.6703e-04.\n",
      "Epoch 85/100\n",
      "Train Loss: 0.0052, Acc: 0.9937\n",
      "Val Loss: 0.1352, Acc: 0.8981, AUC: 0.5646\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 3.3317e-04.\n",
      "Epoch 86/100\n",
      "Train Loss: 0.0019, Acc: 1.0000\n",
      "Val Loss: 0.1311, Acc: 0.8835, AUC: 0.5826\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 3.0150e-04.\n",
      "Epoch 87/100\n",
      "Train Loss: 0.0020, Acc: 0.9958\n",
      "Val Loss: 0.1307, Acc: 0.8786, AUC: 0.5691\n",
      "Val Precision: 0.1250, Recall: 0.0526, F1: 0.0741\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.7205e-04.\n",
      "Epoch 88/100\n",
      "Train Loss: 0.0013, Acc: 1.0000\n",
      "Val Loss: 0.1334, Acc: 0.8786, AUC: 0.5674\n",
      "Val Precision: 0.1250, Recall: 0.0526, F1: 0.0741\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.4484e-04.\n",
      "Epoch 89/100\n",
      "Train Loss: 0.0018, Acc: 1.0000\n",
      "Val Loss: 0.1338, Acc: 0.8835, AUC: 0.5587\n",
      "Val Precision: 0.1429, Recall: 0.0526, F1: 0.0769\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.1991e-04.\n",
      "Epoch 90/100\n",
      "Train Loss: 0.0019, Acc: 0.9979\n",
      "Val Loss: 0.1316, Acc: 0.8835, AUC: 0.5545\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.9728e-04.\n",
      "Epoch 91/100\n",
      "Train Loss: 0.0020, Acc: 0.9979\n",
      "Val Loss: 0.1324, Acc: 0.8883, AUC: 0.5615\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.7697e-04.\n",
      "Epoch 92/100\n",
      "Train Loss: 0.0023, Acc: 0.9979\n",
      "Val Loss: 0.1338, Acc: 0.8835, AUC: 0.5705\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.5900e-04.\n",
      "Epoch 93/100\n",
      "Train Loss: 0.0019, Acc: 0.9979\n",
      "Val Loss: 0.1321, Acc: 0.8883, AUC: 0.5736\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.4340e-04.\n",
      "Epoch 94/100\n",
      "Train Loss: 0.0017, Acc: 1.0000\n",
      "Val Loss: 0.1311, Acc: 0.8883, AUC: 0.5778\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.3016e-04.\n",
      "Epoch 95/100\n",
      "Train Loss: 0.0014, Acc: 1.0000\n",
      "Val Loss: 0.1329, Acc: 0.8786, AUC: 0.5773\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.1932e-04.\n",
      "Epoch 96/100\n",
      "Train Loss: 0.0016, Acc: 1.0000\n",
      "Val Loss: 0.1356, Acc: 0.8835, AUC: 0.5711\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.1087e-04.\n",
      "Epoch 97/100\n",
      "Train Loss: 0.0013, Acc: 1.0000\n",
      "Val Loss: 0.1345, Acc: 0.8835, AUC: 0.5775\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.0483e-04.\n",
      "Epoch 98/100\n",
      "Train Loss: 0.0014, Acc: 1.0000\n",
      "Val Loss: 0.1378, Acc: 0.8883, AUC: 0.5764\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.0121e-04.\n",
      "Epoch 99/100\n",
      "Train Loss: 0.0015, Acc: 0.9979\n",
      "Val Loss: 0.1350, Acc: 0.8883, AUC: 0.5812\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 100/100\n",
      "Train Loss: 0.0018, Acc: 0.9979\n",
      "Val Loss: 0.1382, Acc: 0.8932, AUC: 0.5843\n",
      "Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "--------------------------------------------------\n",
      "0.6771742189698846\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    '''Set all random seeds for reproducibility'''\n",
    "    random.seed(seed)  # Python的random模块\n",
    "    np.random.seed(seed)  # Numpy模块\n",
    "    torch.manual_seed(seed)  # PyTorch CPU\n",
    "    torch.cuda.manual_seed(seed)  # PyTorch GPU\n",
    "    torch.cuda.manual_seed_all(seed)  # PyTorch GPU (多GPU)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # Python hash种子\n",
    "    torch.backends.cudnn.deterministic = True  # 确保每次返回的卷积算法是确定的\n",
    "    torch.backends.cudnn.benchmark = False  # True的话会自动寻找最适合当前配置的高效算法，来达到优化运行效率的问题。False可以保证实验结果的可重现性。\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.75, gamma=2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        # 确保输入形状正确\n",
    "        # inputs = inputs.squeeze()\n",
    "        targets = targets.float()\n",
    "        # print(inputs.shape, targets.shape)\n",
    "        \n",
    "        # 使用 BCEWithLogitsLoss 代替 CrossEntropy\n",
    "        bce_loss = nn.BCEWithLogitsLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * bce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.FloatTensor(y)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class DeepClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=4096, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            # 第一层：4096 -> 2048\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            # 第二层：2048 -> 1024\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            # 第三层：1024 -> 256\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            # 第四层：256 -> 64\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            # 输出层：64 -> 1\n",
    "            nn.Linear(64, 1)  # 二分类问题，使用一个输出节点\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        predictions.extend((torch.sigmoid(outputs) > 0.5).float().cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = total_loss / len(train_loader)\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='binary', zero_division=0)\n",
    "    \n",
    "    return epoch_loss, accuracy, precision, recall, f1\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    probabilities = []\n",
    "    \n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        predictions.extend((probs > 0.5).float().cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        probabilities.extend(probs.cpu().numpy())\n",
    "    \n",
    "    val_loss = total_loss / len(val_loader)\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='binary', zero_division=0)\n",
    "    try:\n",
    "        auc = roc_auc_score(true_labels, probabilities)\n",
    "    except:\n",
    "        auc = 0.0\n",
    "    \n",
    "    return val_loss, accuracy, precision, recall, f1, auc\n",
    "\n",
    "def train_model(X_train, X_test, y_train, y_test, config):\n",
    "    # 数据预处理\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    train_dataset = CustomDataset(X_train_scaled, y_train.values)\n",
    "    test_dataset = CustomDataset(X_test_scaled, y_test.values)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config['batch_size'], \n",
    "        shuffle=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=config['batch_size']\n",
    "    )\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 初始化模型（添加input_dim参数）\n",
    "    model = DeepClassifier(\n",
    "        input_dim=X_train.shape[1],\n",
    "        dropout_rate=config['dropout_rate']\n",
    "    ).to(device)\n",
    "    \n",
    "    criterion = FocalLoss(alpha=config['focal_alpha'], gamma=config['focal_gamma'])\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), \n",
    "        lr=config['learning_rate'], \n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "    \n",
    "    # scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #     optimizer, \n",
    "    #     mode='min', \n",
    "    #     factor=0.5, \n",
    "    #     patience=20, \n",
    "    #     verbose=True\n",
    "    # )\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, \n",
    "        T_max=config['epochs'], \n",
    "        eta_min=0.0001, \n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [], \n",
    "        'val_loss': [], 'val_acc': [],\n",
    "        'val_auc': []\n",
    "    }\n",
    "    \n",
    "    best_val_auc = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(config['epochs']):\n",
    "        train_loss, train_acc, train_prec, train_recall, train_f1 = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, device\n",
    "        )\n",
    "        \n",
    "        val_loss, val_acc, val_prec, val_recall, val_f1, val_auc = validate(\n",
    "            model, test_loader, criterion, device\n",
    "        )\n",
    "        \n",
    "        # scheduler.step(val_loss)\n",
    "        scheduler.step()\n",
    "        \n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_auc'].append(val_auc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{config['epochs']}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, AUC: {val_auc:.4f}\")\n",
    "        print(f\"Val Precision: {val_prec:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}\")\n",
    "        print(\"-\"*50)\n",
    "    \n",
    "    model.load_state_dict(best_model_state)\n",
    "    return model, history\n",
    "\n",
    "# plot_training_history 函数保持不变\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    set_seed(42)\n",
    "    config = {\n",
    "        'batch_size': 32,\n",
    "        'learning_rate': 0.005,\n",
    "        'weight_decay': 1e-4,\n",
    "        'dropout_rate': 0.4,\n",
    "        'epochs': 100,\n",
    "        'focal_alpha': 0.7,\n",
    "        'focal_gamma': 2\n",
    "    }\n",
    "    model, history = train_model(X_train, X_test, y_train, y_test, config)\n",
    "    print(max(history['val_auc']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
